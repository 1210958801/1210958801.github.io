---
layout: post
title: Flume的从无到有
tags: [大数据]
description: 只是一个小小的开端
---

#### 刚开始搭建Flume服务的时候，找了好多网上的博客，要不就是缺胳膊少腿的，要不就是扯一大堆没用的犊子。搞的我乱的一塌糊涂。最终我去了Flume的官方网站。[官方传送门](http://flume.apache.org/FlumeUserGuide.html#complex-flows),虽然是全英文，但是总比走弯路强，所以说以后大家在学东西的时候，不太建议刚一开始就去网上找一大堆别人嚼烂的东西，这样，你理解的东西只局限于他的思维。
## 概要
![介绍](https://user-gold-cdn.xitu.io/2019/3/2/1693d903c944b674?w=2332&h=322&f=png&s=111963)
#### 这是官方的定义,大致意思可以理解为:Flume是一个是一个分布式，可靠且可用的系统，用于有效地从许多不同的源收集、聚合和移动大量日志数据到一个集中式的数据存储区。因为他的数据源是可以扩展的，而且他并不局限于收集日志信息，因此可以用于传输大量事件信息，包括社交媒体网络流量数据、电子邮箱以及一切可能的数据源。而且他还是Apache中的顶级项目。他运行起来其实就是一个java进程。。嗯。。。牛逼吹的挺响。具体看看人家是怎么做的吧。
#### 另外我们需要了解到的是：Apache Flume 是 Apache 基金会的顶级项目，在加入 Apache 之前由 cloudera 公司开发以及维护。Apache Flume 目前有两种主版本： 0.9.x 和 1.x。 其中 0.9.x 是历史版本，我们称之为 Flume OG（original generation）。2011 年 10 月 22 号，cloudera 完成了 Flume-728，对 Flume 进行了里程碑式的改动：重构核心组件、核心配置以及代码架构，重构后的版本统称为 Flume NG（next generation），也就是这里说的 1.x 版本。所以下次别人说Flume NG的时候可别掉面啊！
##### 读完这篇文章你可以了解到的:从Flume的起源+Flume的宏观架构以及内部基本结构+实践
## 第一步:Flume的基本结构
![](https://user-gold-cdn.xitu.io/2019/3/2/1693da04d4a331ed?w=2334&h=934&f=png&s=335200)
### Flume中由四部分组成:
#### Agent(英文的翻译为代理,Flume中我们可以将他理解为一个事实存在的一个杯子这样的一个物体)Source(英文翻译为根源、源头,Flume中我们可以理解为杯子的瓶口)
#### Channel(英文翻译为引导 Flume中我们可以理解为是杯身)
#### Sink(英文翻译为洗涤槽Flume中我们可以理解为将杯子中水倒掉或者倒入其他杯子的这个动作)方才也提到了,其实FlumeAgent就是JVM的进程。他只不过被定义为可以传输字节和可选字符串属性集的数据流单元，他是一个将外部数据源流向下一个目的地的组件。
### 工作流程:
#### Flume的source数据源部分，会消费一些像来自WebServer传递的事件。这些外部数据源会以source可识别的格式将事件发送到source。就像是第一步中我们说的瓶子，他可以当做是一个瓶子的瓶口进水，也可以当做是另外一个瓶子接受水。当Flume Source接受事件的时候，channel会将source接受的数据在本地磁盘或者是内存中做备份。他会一直存储这些数据直到数据被消费。接收器(Sink)将事件从channel中取出会放到一个类似于HDFS的仓库，或者是继续向前到下一个Flume Agent的Source中。
#### 这段话的意思就如同，我们可以将水倒入杯子中，杯中水在倒掉之前是存在于杯子内部的，然后我们可以选择将杯中的水倒入其他的杯子当中(另外一个Agent)，也可以将杯中水倒入一个存放水的容器当中(HDFS等等)，。以上充分的体现了他的灵活性。以上我们就简单的了解了他是如何工作的。下面我们将了解他有哪些零件来让他有工作的条件。
## 第二部:FlumeAgent的原理(参考于:《Flume构建高可用、可扩展的海量日志采集系统》)
#### 每个Source都有自己的Channel处理器，每次Source将数据写入Channel的之前，都会通过Channel处理器，然后Channel处理器将这些事件传到一个或者多个Source配置的拦截器中。Source事件的拦截器其实就是一段代码，它主要的作用就是读取事件然后根据一定的标准，比如正则，来删除事件。也可以为时间添加报头和移除现有的报头(路由的意图和跟踪发送时间的优先级和严重性)。一旦拦截器执行完毕之后，就会传输到Channel选择器当中，他的作用是用来决定哪些事件必须写入哪些Channel的，以及哪些事件是必须/可选的。一旦从Source中写出事件，Channel处理器会发送事件回执(ACK)给Source，以继续接受更多的事件。
![](https://user-gold-cdn.xitu.io/2019/5/8/16a963156fb67cf5?w=1740&h=1024&f=png&s=642449)
#### Sink运行器中有一个Sink组(未设置的时候不会存在),每个Sink组下都有一个Sink处理器,这个运行器主要是干啥那？因为每一个Channel只能对应一个Sink，所以他是做这个的。让每个Channel和与之匹配的Sink连接起来，如果多个Sink从一个Channel中获取数据,选定的Sink从Channel中接受事件,并将事件写入到下一个阶段或最终的目的地。
![](https://user-gold-cdn.xitu.io/2019/5/8/16a96391faa6d83f?w=1810&h=1136&f=png&s=442361)
## 第三步:常用三大组件的类型
### 1、Source(配置详解请移步官网，其他博客仅供参考)
#### Avro Source:可以从Avro(是一个基于二进制数据传输的高性能中间件，是 hadoop 的一个子项目)接受Avro事件
#### Thrift Source:一个可以设置安全启动的source,通过设置参数他可以实现进行身份验证，只有验证通过或者已经验证过的数据源通信。
#### Exec Source:执行源,可以执行在启动之前给定的命令。并且可以标准输出连续生成数据。其实他执行的就是一个命令，但是有一个问题，如果执行命令的进程因为任何原因退出，那么源也不会生成其他数据。
#### Spooling Directory Source:可以通过配置相关目录，摄取目录中文件的内容。
#### Kafka Source:Flume和Kafka之间的通信渠道支持安全认证和数据加密，数据加密由SSL/TLS提供。
### 2、Channels(配置详解请移步官网，其他博客仅供参考)
#### Memory Channel:事件存储在具有可配置最大大小的内存队列中。适用场景：需要更高吞吐量并准备在代理故障的情况下丢失上载数据的流的理想选择。缺点：Memory Channel是一个不稳定的隧道，它在内存中存储所有事件。如果进程异常停止，内存中的数据将不能让恢复。受内存大小的限制。
#### Flie channel:是一个持久化的channel，数据安全并且只要磁盘空间足够，它就可以将数据存储到磁盘上
#### JDBC Channel:事件被持久存储在可靠的数据库中。目前支持嵌入式的Derby数据库。如果可恢复性非常的重要可以使用这种方式。
### 3、Sinks(配置详解请移步官网，其他博客仅供参考)
#### HDFS sink: 此接收器将事件写入Hadoop分布式文件系统（HDFS）。 它目前支持创建文本和序列文件。以及文件压缩，可以基于经过的时间或数据大小或事件数量来周期性地滚动文件（关闭当前文件并创建新文件）。它还通过属性（例如事件发生的时间戳或机器）来对数据进行分区。 HDFS目录路径可能包含将由HDFS接收器替换的格式化转义序列,以生成用于存储事件的目录/文件名。 使用此接收器需要安装hadoop。
#### Hive sink:此接收器将包含定界文本或JSON数据的事件直接传输到Hive表或分区。 事件使用Hive事务写入。 一旦将一组事件提交给Hive，它们就立即对Hive查询可见。 flume将流入的分区可以是预创建的，或者，如果缺少，Flume可以创建它们。 来自传入事件数据的字段映射到Hive表中的相应列。
#### Hbase sink:把数据写入hbase(columnFamily) 
#### avro sink:avro sink形成了Flume分层收集支持的一半。 发送到此接收器的Flume事件将转换为Avro事件并发送到配置的主机名/端口对。 事件从已配置的通道以批量配置的批处理大小获取
#### kafka sink:把数据写入kafka对应的topic中。
## Last
#### 到这里我们对FLume的了解就结束了。其实就是如此的简单,其余的不过就是在碰到问题的时候解决罢了,将你的问题评论我们一起解决。
#### 强烈建议大家通过搭建集群练练手，我也是弄的多台，但不是多台服务器，而是多个Flume。为了节省资源，我在我自己的Linux系统上弄了两个Flume。每天早上定时从公司测试服务器上拉取日志，然后第一个Flume监听到日志文件更新了，就会将日志传输到第二个上，第二个Flume就会将日志发送到HDFS上。

### 流程图以及详细的配置(按照数据流的顺序展示,重点看一下两个衔接的部分以及第二个Flume_Sink部分)

![](https://user-gold-cdn.xitu.io/2019/3/13/16976668686b02b5?w=1422&h=358&f=png&s=29470)

```
# definition sources,channels and sinks
firstagent.sources = first_source1
firstagent.channels = first_channel1
firstagent.sinks = first_sink1

# set up sources
firstagent.sources.first_source1.type = spooldir
firstagent.sources.first_source1.spoolDir = /usr/local/log/
firstagent.sources.first_source1.fileHeader = true

# set up channels
firstagent.channels.first_channel1.type = memory
#firstagent.channels.first_channel1.capacity = 10000
#firstagent.channels.first_channel1.transactionCapacity = 10000
#firstagent.channels.first_channel1.byteCapacityBufferPercentage = 20
#firstagent.channels.first_channel1.byteCapacity = 800000

# set up sinks
firstagent.sinks.first_sink1.type = avro
firstagent.sinks.first_sink1.hostname = 192.168.20.88
firstagent.sinks.first_sink1.port = 8888

# set up connection
firstagent.sources.first_source1.channels = first_channel1
firstagent.sinks.first_sink1.channel = first_channel1
```

```
# definition sources,channels and sinks
secondagent.sources = second_source1
secondagent.channels = second_channel1
secondagent.sinks = second_sink1

# set up sources
secondagent.sources.second_source1.type = avro
secondagent.sources.second_source1.bind = 192.168.20.88
secondagent.sources.second_source1.port = 8888

# set up channels
secondagent.channels.second_channel1.type = memory
secondagent.channels.second_channel1.capacity = 10000
secondagent.channels.second_channel1.transactionCapacity = 10000
secondagent.channels.second_channel1.byteCapacityBufferPercentage = 20
secondagent.channels.second_channel1.byteCapacity = 800000

# set up sinks
secondagent.sinks.second_sink1.type = hdfs
secondagent.sinks.second_sink1.hdfs.path = /flume/events/%y-%m-%d/%H%M/%S
secondagent.sinks.second_sink1.hdfs.filePrefix = events_
# 是否启用时间上的“舍弃”
secondagent.sinks.second_sink1.hdfs.round = true
# 时间上舍弃的值
secondagent.sinks.second_sink1.roundValue = 10
# 时间上进行舍弃的单位
secondagent.sinks.second_sink1.hdfs.roundUnit = minute
# 是否使用当地时间
secondagent.sinks.second_sink1.hdfs.useLocalTimeStamp = true
# 写文件的格式
secondagent.sinks.second_sink1.hdfs.writeFormat = Text
# 文件类型
secondagent.sinks.second_sink1.hdfs.fileType = DataStream
# 当events数据达到该数量时候，将临时文件滚动成目标文件 如果设置为0则表示不根据events数据来滚动文件
secondagent.sinks.second_sink1.hdfs.rollCount = 0
# 当临时文件达到该大小（单位：bytes）时，滚动成目标文件; 如果设置成0，则表示不根据临时文件大小来滚动文件
secondagent.sinks.second_sink1.hdfs.rollSize = 0
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
secondagent.sinks.second_sink1.hdfs.rollInterval = 600
# 每个批次刷新到HDFS上的events数量；
secondagent.sinks.second_sink1.hdfs.batchSize = 100
# hdfs sink启动的操作HDFS的线程数。
secondagent.sinks.second_sink1.hdfs.threadsPoolSize = 10
# 当目前被打开的临时文件在该参数指定的时间（秒）内，没有任何数据写入，则将该临时文件关闭并重命名成目标文件；
secondagent.sinks.second_sink1.hdfs.idleTimeout = 0
# 写入HDFS文件块的最小副本数。该参数会影响文件的滚动配置，一般将该参数配置成1，才可以按照配置正确滚动文件。
secondagent.sinks.second_sink1.hdfs.minBlockReplicas = 1

# set up connection
secondagent.sources.second_source1.channels = second_channel1
secondagent.sinks.second_sink1.channel = second_channel1
```
***
## Flume的安装
### 话不多说，先来一张图表明心意
![系统要求](https://user-gold-cdn.xitu.io/2019/3/2/1693d98a7c91745f?w=1458&h=284&f=png&s=72106)
#### 说白了其实还是，对环境和内存、磁盘空间以及对文件权限的要求罢了。而且这些要求都是硬性的,所以在安装之前请检查是否一致,尤其是版本。这个东西就好像我们下载游戏之前，不都有一个机器最低配置嘛!，比如我之前的电脑就带不起来GTAV,为了这个游戏心心念念的买了一个游戏本,结果哇靠3D眩晕。评论可以分享一下那些年做过的囧事😳。注意:不要忘记配置JDK的环境变量。
#### 重要的事情讲三遍:"官方、官方、官方"。[官方下载让那些三流链接死去吧](http://flume.apache.org/download.html)有的时候我们上百度搜XX.jar/XXX，一堆。。然后点进去一个链接竟然是CSDN的下载路径。然后他还和你要CSDN的C币和积分。这个我就很烦了。毕竟，之前刚出道的时候也用积分买过,这个梗我一辈子都忘不了MMP。
#### 下载下来之后，如果是MacOS请用scp上传，如果是Windows建议用FTP/SFTP(不太建议使用pscp)之后解压....
#### 解压完之后我们就可以看到Flume的包了,再配置环境变量。其中我们需要关注的就只是conf文件夹下的flume.conf、flume-env.sh两个文件(如果没有，请自行创建或者执行以下命令)
```
cp flume-conf.properties.template flume.conf
cp flume-env.sh.template flume-env.sh
```
#### 然后我们先来配置flume-env.sh文件具体内容如下
```
export JAVA_HOME=/usr/local/jdk1.8
```
#### 没错就只是一个Java的环境变量，因为他依托于JVM嘛。
#### 之后Flume.conf里边写的内容就是我上边发的那俩实例了，具体怎么配置看自己的业务场景需要。
#### 配置完成之后，执行(注意这条命令只是示例,具体看自己的flume-ng执行文件位置和agent的名字以及flume.conf配置文件的位置,如果需要配置其他请移步官方{命令这个东西可以查查其他链接，因为官方命令这一块写的也是很少，不过得找那种靠谱的博主})
```
./bin/flume-ng agent --name firstagent --conf conf --conf-file ./conf/flume.conf -Dflume.root.logger=INFO,console &
```
#### The End，没错，就这么简单，整个安装过程就这么少。
***
## 分割线以下记录发生过的问题，以及解决方案。