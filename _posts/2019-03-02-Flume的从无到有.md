---
layout: post
title: Flume的从无到有
categories: [技术]
tags: [大数据]
description: 只是一个小小的开端
---

#### 刚开始搭建Flume服务的时候，找了好多网上的博客，要不就是缺胳膊少腿的，要不就是扯一大堆没用的犊子。搞的我乱的一塌糊涂。最终我去了Flume的官方网站。[官方传送门](http://flume.apache.org/FlumeUserGuide.html#complex-flows),虽然是全英文，但是总比走弯路强，所以说以后大家在学东西的时候，不太建议刚一开始就去网上找一大堆别人嚼烂的东西，这样，你理解的东西只局限于他的思维。
## 第一步:名词解析
#### Source(英文翻译为根源、源头,Flume中我们可以理解为一个瓶子的瓶口)
#### Channel(英文翻译为引导 Flume中我们可以理解为是瓶身)
#### Sink(英文翻译为洗涤槽 Flume中我们可以理解为将瓶中水倒掉或者倒入其他瓶子的这个动作)
## 好了，我们先开始第二步:介绍Flume
![介绍](https://user-gold-cdn.xitu.io/2019/3/2/1693d903c944b674?w=2332&h=322&f=png&s=111963)
#### 官方这段话的基本意思就是:Flume是一个高可用的分布式系统，可以收集大量数据，而且可以将不同的数据源转移到集中数据存储中。因为他的数据源是可以扩展的，而且他并不局限于收集日志信息，因此可以用于传输大量事件信息，包括社交媒体网络流量数据、电子邮箱以及一切可能的数据源。而且他还是Apache中的顶级项目。嗯。。。牛逼吹的挺响。具体看看人家是怎么做的吧。
#### 他运行起来就是一个java进程。所以在他的系统要求中是这样描述的。
![](https://user-gold-cdn.xitu.io/2019/3/2/1693d98a7c91745f?w=1458&h=284&f=png&s=72106)
#### 说白了其实还是，对环境和内存、磁盘空间以及对文件权限的要求罢了。就好像我们下载游戏之前，不都有一个机器最低配置嘛!，比如我之前的电脑就带不起来GTAV。注意:不要忘记配置JDK的环境变量。
## 第三步:Flume的基本结构
![](https://user-gold-cdn.xitu.io/2019/3/2/1693da04d4a331ed?w=2334&h=934&f=png&s=335200)
#### 方才也提到了,其实Flume Agent就是JVM的进程。他只不过被定义为可以传输字节和可选字符串属性集的数据流单元，他是一个将外部数据源流向下一个目的地的组件。工作流程:Flume的source数据源部分，会消费一些像来自WebServer传递的事件。这些外部数据源会以source可识别的格式将事件发送到source。就像是第一步中我们说的瓶子，他可以当做是一个瓶子的瓶口进水，也可以当做是另外一个瓶子接受水。当Flume Source接受事件的时候，channel会将source接受的数据在本地磁盘或者是内存中做备份。他会一直存储这些数据直到数据被消费。接收器(Sink)将事件从channel中取出会放到一个类似于HDFS的仓库，或者是继续向前到下一个Flume Agent的Source中。这段话的意思就如同，我们可以将水倒入瓶中，或选择在瓶中停留片刻，然后再将瓶中的水倒入其他的瓶子当中，也可以将水保留到当前的瓶子当中。以上充分的体现了他的灵活性。

## 第四步:常用三大组件的类型
### 1、Source(配置详解请移步官网，其他博客仅供参考)

#### Avro Source:可以从Avro(是一个基于二进制数据传输的高性能中间件，是 hadoop 的一个子项目)接受Avro事件
#### Thrift Source:一个可以设置安全启动的source,通过设置参数他可以实现进行身份验证，只有验证通过或者已经验证过的数据源通信。
#### Exec Source:执行源,可以执行在启动之前给定的命令。并且可以标准输出连续生成数据。其实他执行的就是一个命令，但是有一个问题，如果执行命令的进程因为任何原因退出，那么源也不会生成其他数据。
#### Spooling Directory Source:可以通过配置相关目录，摄取目录中文件的内容。
#### Kafka Source:Flume和Kafka之间的通信渠道支持安全认证和数据加密，数据加密由SSL/TLS提供。

### 2、Channels(配置详解请移步官网，其他博客仅供参考)

#### Memory Channel:事件存储在具有可配置最大大小的内存队列中。适用场景：需要更高吞吐量并准备在代理故障的情况下丢失上载数据的流的理想选择。缺点：Memory Channel是一个不稳定的隧道，它在内存中存储所有事件。如果进程异常停止，内存中的数据将不能让恢复。受内存大小的限制。
#### Flie channel:是一个持久化的channel，数据安全并且只要磁盘空间足够，它就可以将数据存储到磁盘上
#### JDBC Channel:事件被持久存储在可靠的数据库中。目前支持嵌入式的Derby数据库。如果可恢复性非常的重要可以使用这种方式。

### 3、Sinks(配置详解请移步官网，其他博客仅供参考)

#### HDFS sink: 此接收器将事件写入Hadoop分布式文件系统（HDFS）。 它目前支持创建文本和序列文件。以及文件压缩，可以基于经过的时间或数据大小或事件数量来周期性地滚动文件（关闭当前文件并创建新文件）。它还通过属性（例如事件发生的时间戳或机器）来对数据进行分区。 HDFS目录路径可能包含将由HDFS接收器替换的格式化转义序列,以生成用于存储事件的目录/文件名。 使用此接收器需要安装hadoop。
#### Hive sink:此接收器将包含定界文本或JSON数据的事件直接传输到Hive表或分区。 事件使用Hive事务写入。 一旦将一组事件提交给Hive，它们就立即对Hive查询可见。 flume将流入的分区可以是预创建的，或者，如果缺少，Flume可以创建它们。 来自传入事件数据的字段映射到Hive表中的相应列。
#### Hbase sink:把数据写入hbase(columnFamily) 
#### avro sink:avro sink形成了Flume分层收集支持的一半。 发送到此接收器的Flume事件将转换为Avro事件并发送到配置的主机名/端口对。 事件从已配置的通道以批量配置的批处理大小获取
#### kafka sink:把数据写入kafka对应的topic中。

## Last

#### 建议大家通过搭建集群练练手，我也是弄的多台，但是不是多台服务器，而是多个Flume。为了节省资源，我在我自己的Linux系统上弄了两个Flume。每天早上定时从公司测试服务器上拉取日志，然后第一个Flume监听到日志文件更新了，就会将日志传输到第二个上，第二个Flume就会将日志发送到HDFS上。

### 流程图

![](https://user-gold-cdn.xitu.io/2019/3/13/16976668686b02b5?w=1422&h=358&f=png&s=29470)

### 按照Flume的排列顺序看一下基本的配置(重点看一下两个衔接的部分以及第二个Flume_Sink部分)
![](https://user-gold-cdn.xitu.io/2019/3/13/169766849ab20beb?w=1026&h=688&f=png&s=121800)

![](https://user-gold-cdn.xitu.io/2019/3/13/169766abc1930109?w=1512&h=1436&f=png&s=416575)